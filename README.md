# Gesture-Controlled-Speaking-Assistance-for-Deaf-Mute
An Microcontroller(Arduino) based Project for Deaf-Mute People.  

The main aim of this project is to present a system that can efficiently interpret Sign Language gestures to both text and auditory speech. We have focused on designing a Human Computer Interface (HCI) system that can understand the sign language accurately so that the signing people may communicate with the non signing people without the need of an interpreter. It can be used to generate speech or text. The converter here makes use of a glove based technique consisting of flex sensors. The device translates alphabets as well as can form words using specific gestures made by the person.

### Dependencies -   
TMRpcm Library - https://github.com/TMRh20/TMRpcm.git  

Clone the dependencies and put them in your `/Libraries` folder of the IDE.
